<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Co-host /w Vision & Voice - Social Stream Ninja</title>
    <meta name="description" content="Experience real-time AI video conversations with Google's Gemini Vision AI. This interactive demo showcases live video analysis and natural language processing capabilities.">
    <meta name="keywords" content="Gemini AI, video chat, AI assistant, Google AI, computer vision, real-time AI">
    <meta name="robots" content="index, follow">
    <meta property="og:title" content="Gemini Vision Chat">
    <meta property="og:description" content="Live video conversations with Google's Gemini Vision AI">
    <meta property="og:type" content="website">
    <meta name="author" content="Steve Seguin">
    <link rel="me" href="https://github.com/steveseguin">
    <meta property="article:author" content="https://github.com/steveseguin">
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA2NCA2NCI+PGRlZnM+PGxpbmVhckdyYWRpZW50IGlkPSJnMSIgeDE9IjAlIiB5MT0iMCUiIHgyPSIxMDAlIiB5Mj0iMTAwJSI+PHN0b3Agb2Zmc2V0PSIwJSIgc3R5bGU9InN0b3AtY29sb3I6IzQwNEVFRCIvPjxzdG9wIG9mZnNldD0iMTAwJSIgc3R5bGU9InN0b3AtY29sb3I6IzU4NjVGMiIvPjwvbGluZWFyR3JhZGllbnQ+PC9kZWZzPjxwYXRoIGQ9Ik04IDhoNDh2MzhIMjJMOCA1NlY4eiIgZmlsbD0idXJsKCNnMSkiLz48cGF0aCBkPSJNMjAgMjhoMjRNMjAgMjBoMjRNMjAgMzZoMTYiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSI0IiBzdHJva2UtbGluZWNhcD0icm91bmQiLz48Y2lyY2xlIGN4PSI0OCIgY3k9IjM2IiByPSIzIiBmaWxsPSIjZmZmIi8+PC9zdmc+">
<style>
body {
    margin: 0;
    padding: 20px;
    display: flex;
    height: 100vh;
    box-sizing: border-box;
    font-family: system-ui, -apple-system, sans-serif;
    background: #1a1a1a;
    color: #e0e0e0;
    position: relative;
}
.github-link {
    position: fixed;
    bottom: 15px;
    right: 15px;
    opacity: 0.7;
    transition: opacity 0.2s;
}
.github-link:hover {
    opacity: 1;
}
p {
    display: inline-block;
}
.left-panel {
    width: 50%;
    padding-right: 20px;
}
.right-panel {
    width: 50%;
    display: flex;
    flex-direction: column;
    height: 100%;
}
.controls {
    margin-bottom: 20px;
    display: flex;
    gap: 10px;
    flex-wrap: wrap;
}
.preview {
    width: 100%;
    max-height: calc(100vh - 300px);
    object-fit: contain;
    border-radius: 12px;
    background: #2a2a2a;
}
#error {
    color: #ff6b6b;
    margin: 10px 0;
}
select, button, .api-key, .message-input {
    background: #2a2a2a;
    border: 1px solid #404040;
    color: #e0e0e0;
    padding: 8px 12px;
    border-radius: 8px;
    font-size: 14px;
    transition: all 0.2s ease;
}
select:hover, button:hover {
    background: #333;
    border-color: #505050;
}
button {
    cursor: pointer;
    background: #404eed;
    border: none;
    font-weight: 500;
}
button:hover {
    background: #5865f2;
}
#startButton {
    background: #22c55e;
    font-size: 16px;
    padding: 10px 20px;
    font-weight: 600;
    animation: pulse 2s infinite;
}
#startButton:hover {
    background: #16a34a;
}
#startButton {
    background: #22c55e;
    font-size: 16px;
    padding: 10px 20px;
    font-weight: 600;
    animation: pulse 2s infinite;
}
#startButton[data-started="true"] {
    background: #c5225e;
}
#startButton[data-started="true"]:hover {
    background: #a3164a;
}

@keyframes pulse {
    0% { transform: scale(1); }
    50% { transform: scale(1.05); }
    100% { transform: scale(1); }
}
.api-key.highlight {
    border-color: #ff6b6b;
    outline: none;
    box-shadow: 0 0 0 2px rgba(255, 107, 107, 0.3);
}
.api-key-container {
    display: flex;
    flex-direction: row;
    gap: 8px;
}
.api-key-info {
    font-size: 13px;
    color: #a0a0a0;
	margin: auto;
}
.api-key-info a {
    color: #5865f2;
    text-decoration: none;
}
.api-key-info a:hover {
    text-decoration: underline;
}
button:disabled {
    opacity: 0.5;
    cursor: not-allowed;
    background: #251f1f;
}
.chat-container {
    display: flex;
    flex-direction: column;
    height: 100%;
    background: #2a2a2a;
    border-radius: 12px;
    overflow: hidden;
}
.responses {
    flex-grow: 1;
    padding: 16px;
    background: #2a2a2a;
    overflow-y: auto;
    margin-bottom: 10px;
}
.input-container {
    display: flex;
    gap: 10px;
    padding: 16px;
    background: #232323;
    border-top: 1px solid #404040;
}
.message {
    margin: 8px 0;
    padding: 12px;
    border-radius: 8px;
    line-height: 1.5;
}
.user-message {
    background: #404eed;
    margin-left: 20px;
    color: #fff;
}
.assistant-message {
    background: #333;
    margin-right: 20px;
}
.markdown-content {
    white-space: pre-wrap;
    word-wrap: break-word;
}
.markdown-content li {
    margin-left: 20px;
    margin-bottom: 5px;
}
.markdown-content code {
    background: #232323;
    padding: 2px 6px;
    border-radius: 4px;
    font-family: ui-monospace, monospace;
    font-size: 0.9em;
}
.responses::-webkit-scrollbar {
    width: 8px;
}
.responses::-webkit-scrollbar-track {
    background: #232323;
    border-radius: 4px;
}
.responses::-webkit-scrollbar-thumb {
    background: #404040;
    border-radius: 4px;
}
.responses::-webkit-scrollbar-thumb:hover {
    background: #505050;
}


.mute-button:hover {
    background: #333;
    border-color: #505050;
}

.mute-button.muted {
    background: #c5225e;
    border-color: #a3164a;
}

.mute-button.muted:hover {
    background: #a3164a;
}

.mute-controls {
    display: flex;
    gap: 10px;
    align-items: center;
    height: 35px;
}

.mute-button {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 6px;
    background: #2a2a2a;
    border: 1px solid #404040;
    color: #e0e0e0;
    padding: 8px;
    height: 35px;
    border-radius: 8px;
    font-size: 14px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.mute-icon {
    width: 20px;
    height: 20px;
    position: relative;
    display: flex;
    align-items: center;
    justify-content: center;
    margin: auto;
}

.mute-icon::before {
    content: '';
    position: absolute;
    width: 100%;
    height: 100%;
    background-size: contain;
    background-repeat: no-repeat;
}

.mic-icon::before {
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='%23e0e0e0' viewBox='0 0 24 24'%3E%3Cpath d='M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm-1-9c0-.55.45-1 1-1s1 .45 1 1v6c0 .55-.45 1-1 1s-1-.45-1-1V5z'/%3E%3Cpath d='M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z'/%3E%3C/svg%3E");
}

.mic-icon.muted::before {
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='%23e0e0e0' viewBox='0 0 24 24'%3E%3Cpath d='M19 11h-1.7c0 .74-.16 1.43-.43 2.05l1.23 1.23c.56-.98.9-2.09.9-3.28zm-4.02.17c0-.06.02-.11.02-.17V5c0-1.66-1.34-3-3-3S9 3.34 9 5v.18l5.98 5.99zM4.27 3L3 4.27l6.01 6.01V11c0 1.66 1.33 3 2.99 3 .22 0 .44-.03.65-.08l1.66 1.66c-.71.33-1.5.52-2.31.52-2.76 0-5.3-2.1-5.3-5.1H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c.91-.13 1.77-.45 2.54-.9l4.19 4.18L21 20.73 4.27 3z'/%3E%3C/svg%3E");
}

.speaker-icon::before {
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='%23e0e0e0' viewBox='0 0 24 24'%3E%3Cpath d='M3 9v6h4l5 5V4L7 9H3zm13.5 3c0-1.77-1.02-3.29-2.5-4.03v8.05c1.48-.73 2.5-2.25 2.5-4.02zM14 3.23v2.06c2.89.86 5 3.54 5 6.71s-2.11 5.85-5 6.71v2.06c4.01-.91 7-4.49 7-8.77s-2.99-7.86-7-8.77z'/%3E%3C/svg%3E");
}

.speaker-icon.muted::before {
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='%23e0e0e0' viewBox='0 0 24 24'%3E%3Cpath d='M16.5 12c0-1.77-1.02-3.29-2.5-4.03v2.21l2.45 2.45c.03-.2.05-.41.05-.63zm2.5 0c0 .94-.2 1.82-.54 2.64l1.51 1.51C20.63 14.91 21 13.5 21 12c0-4.28-2.99-7.86-7-8.77v2.06c2.89.86 5 3.54 5 6.71zM4.27 3L3 4.27 7.73 9H3v6h4l5 5v-6.73l4.25 4.25c-.67.52-1.42.93-2.25 1.18v2.06c1.38-.31 2.63-.95 3.69-1.81L19.73 21 21 19.73l-9-9L4.27 3zM12 4L9.91 6.09 12 8.18V4z'/%3E%3C/svg%3E");
}

.video-icon::before {
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='%23e0e0e0' viewBox='0 0 24 24'%3E%3Cpath d='M17 10.5V7c0-.55-.45-1-1-1H4c-.55 0-1 .45-1 1v10c0 .55.45 1 1 1h12c.55 0 1-.45 1-1v-3.5l4 4v-11l-4 4z'/%3E%3C/svg%3E");
}

.video-icon.muted::before {
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='%23e0e0e0' viewBox='0 0 24 24'%3E%3Cpath d='M21 6.5l-4 4V7c0-.55-.45-1-1-1H9.82L21 17.18V6.5zM3.27 2L2 3.27 4.73 6H4c-.55 0-1 .45-1 1v10c0 .55.45 1 1 1h12c.21 0 .39-.08.54-.18L19.73 21 21 19.73 3.27 2z'/%3E%3C/svg%3E");
}

:root {
  --puppet-primary: #333;
  --puppet-bg: #74d0ee;
  --puppet-accent: #4a4a4a;
  --puppet-highlight: #fff;
  --puppet-shadow: rgba(0, 0, 0, 0.2);
}
#puppet-container {
    position: fixed;
    z-index: 1000;
}
.puppet {
  width: 300px;
  height: 300px;
  position: relative;
  background: radial-gradient(circle at 30% 30%, var(--puppet-bg) 0%, #e0e0e0 100%);
  border-radius: 50%;
  transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
  box-shadow: 0 10px 30px var(--puppet-shadow);
}

.face {
  position: absolute;
  left: 50%;
  top: 50%;
  transform: translate(-50%, -50%);
  transition: transform 0.3s ease;
}

.eyes {
  display: flex;
  gap: 40px;
  transition: all 0.3s ease;
}

.eye {
  width: 32px;
  height: 32px;
  background: var(--puppet-primary);
  border-radius: 50%;
  position: relative;
  transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
  overflow: hidden;
}

.eye::before {
  content: '';
  position: absolute;
  width: 10px;
  height: 10px;
  background: var(--puppet-highlight);
  border-radius: 50%;
  top: 5px;
  left: 5px;
  transition: all 0.3s ease;
}

.eye::after {
  content: '';
  position: absolute;
  width: 100%;
  height: 100%;
  background: var(--puppet-bg);
  transform: translateY(-100%);
  transition: transform 0.15s ease;
}

.eyebrows {
  position: absolute;
  width: 100%;
  top: -20px;
  display: flex;
  justify-content: space-between;
  padding: 0 10px;
}

.eyebrow {
  width: 35px;
  height: 8px;
  background: var(--puppet-primary);
  border-radius: 4px;
  transition: all 0.3s ease;
  transform-origin: center;
  opacity: 0;
}

.mouth {
  width: 80px;
  height: 40px;
  border: 6px solid var(--puppet-primary);
  border-radius: 0 0 40px 40px;
  border-top: 0;
  margin: 25px auto;
  transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
  position: relative;
  transform-origin: center;
  margin-top: 32px;
}

.cheeks {
  position: absolute;
  width: 100%;
  top: 34%;
  display: flex;
  justify-content: space-between;
  padding: 0 20px;
  opacity: 0;
  transition: all 0.3s ease;
  left: -19%;
}

.cheek {
  width: 25px;
  height: 15px;
  background: #ff9999;
  border-radius: 50%;
  transform: scale(0);
  transition: all 0.3s ease;
  
}

@keyframes talking {
  0%, 100% { 
    height: 30px; 
    width: 65px;
    border-radius: 32.5px;
  }
  50% { 
    height: 50px; 
    width: 55px;
    border-radius: 27.5px;
  }
}

@keyframes softTalking {
  0%, 100% { 
    height: 40px;
    transform: scale(1);
  }
  50% { 
    height: 50px;
    transform: scale(0.98);
  }
}

@keyframes blink {
  0% { transform: translateY(-100%); }
  50% { transform: translateY(0); }
  100% { transform: translateY(100%); }
}

@keyframes bounce {
  0%, 100% { transform: translate(-50%, -50%); }
  50% { transform: translate(-50%, -47%); }
}

@keyframes breathe {
  0%, 100% { transform: scale(1); }
  50% { transform: scale(1.02); }
}

@keyframes idle {
  0%, 100% { transform: translate(-50%, -50%) rotate(0deg); }
  25% { transform: translate(-51%, -50%) rotate(-0.5deg); }
  75% { transform: translate(-49%, -50%) rotate(0.5deg); }
}

.puppet {
  animation: breathe 4s ease-in-out infinite;
}

.face {
  animation: idle 6s ease-in-out infinite;
}

.talking .mouth {
  animation: talking 0.4s infinite;
}

.blink .eye::after {
  animation: blink 0.15s ease forwards;
}

.happy .mouth {
  height: 60px;
  border-radius: 0 0 80px 80px;
  transform: translateY(0px) scale(0.9);
}

.happy .cheeks {
  opacity: 1;
}

.happy .cheek {
  transform: scale(1);
}

.happy.talking .mouth {
  animation: softTalking 0.4s infinite;
}

.sad .mouth {
  transform: rotate(180deg) translateY(-20px) scale(0.8);
  width: 60px;
  height: 30px;
}

.sad .eyebrows {
  opacity: 1;
}

.sad .eyebrow {
  transform: rotate(-15deg) translateY(5px);
  opacity: 1;
}

.sad .eyebrow:last-child {
  transform: rotate(15deg) translateY(5px);
}

.surprised .mouth {
  height: 80px;
  width: 60px;
  border-radius: 50%;
  transform: translateY(5px);
}

.surprised .eye {
  height: 45px;
  width: 45px;
  transform: translateY(-5px);
}

.surprised .eyebrows {
  opacity: 1;
}

.surprised .eyebrow {
  transform: translateY(-5px);
  opacity: 1;
}

.angry .eyebrows {
  opacity: 1;
}

.angry .eyebrow {
  transform: rotate(30deg) translateY(-2px);
  opacity: 1;
}

.angry .eyebrow:last-child {
  transform: rotate(-30deg) translateY(-2px);
}

.angry .mouth {
  width: 60px;
  height: 20px;
  transform: rotate(-10deg) translateY(10px);
  border-radius: 0 0 20px 20px;
}

.angry .eye::before {
  width: 8px;
  height: 8px;
  top: 12px;
  left: 12px;
}

.thinking .eye {
  height: 12px;
  border-radius: 6px;
  transform: translateY(5px);
}

.thinking .mouth {
  width: 40px;
  height: 12px;
  border-radius: 6px;
  transform: rotate(-10deg) translate(20px, 10px);
}

.thinking .eyebrows {
  opacity: 1;
}

.thinking .eyebrow:last-child {
  transform: rotate(-15deg) translateY(-2px);
  opacity: 1;
}

.wink .eye:first-child {
  height: 5px;
  margin-top: 15px;
  border-radius: 5px;
}

.excited .face {
  animation: bounce 0.4s infinite;
}

.excited .cheeks {
  opacity: 1;
}

.excited .cheek {
  transform: scale(1.2);
  background: #ff7777;
}

.sleepy .eye {
  height: 8px;
  border-radius: 4px;
  transform: translateY(12px);
}

.sleepy .mouth {
  height: 25px;
  width: 40px;
  transform: translateY(10px);
}

.shadow {
  position: absolute;
  bottom: -15px;
  left: 50%;
  transform: translateX(-50%);
  width: 90%;
  height: 20px;
  background: var(--puppet-shadow);
  border-radius: 50%;
  transition: all 0.3s ease;
  filter: blur(5px);
}

.excited .shadow {
  width: 85%;
  opacity: 0.8;
  transform: translateX(-50%) scaleX(0.95);
}

[data-theme="dark"] {
  --puppet-primary: #fff;
  --puppet-bg: #2a2a2a;
  --puppet-accent: #dadada;
  --puppet-highlight: #333;
  --puppet-shadow: rgba(0, 0, 0, 0.4);
}

.puppet * {
  transition: all 0.35s cubic-bezier(0.4, 0, 0.2, 1);
}

.desktop-capturer-selection {
	position: fixed;
	top: 0;
	left: 0;
	width: 100%;
	height: 100vh;
	background: rgba(30,30,30,.75);
	color: #fff;
	z-index: 10000000;
	display: flex;
	align-items: center;
	justify-content: center;
}
.desktop-capturer-selection__scroller {
	width: 100%;
	max-height: 100vh;
	overflow-y: auto;
}
.desktop-capturer-selection__list {
	max-width: calc(100% - 100px);
	margin: 50px;
	padding: 0;
	display: flex;
	flex-wrap: wrap;
	list-style: none;
	overflow: hidden;
	justify-content: center;
}
.desktop-capturer-selection__item {
	display: flex;
	margin: 4px;
}
.desktop-capturer-selection__btn {
	display: flex;
	flex-direction: column;
	align-items: stretch;
	width: 145px;
	margin: 0;
	border: 0;
	border-radius: 3px;
	padding: 4px;
	background: #252626;
	text-align: left;
	transition: background-color .15s, box-shadow .15s;
}
.desktop-capturer-selection__btn:hover,
.desktop-capturer-selection__btn:focus {
	background: rgba(98,100,167,.8);
}
.desktop-capturer-selection__thumbnail {
	width: 100%;
	height: 81px;
	object-fit: cover;
}
.desktop-capturer-selection__name {
	margin: 6px 0 6px;
	white-space: nowrap;
	text-overflow: ellipsis;
	overflow: hidden;
}
#apiKey {
	webkitTextSecurity:disc{	
}

</style>
</head>
<body>
    <div class="left-panel">
        <div class="controls">
			<select id="videoSource"></select>
			<select id="audioSource"></select>
			<div class="mute-controls" style="display: flex; gap: 10px;">
				<button id="muteMic" class="mute-button">
					<div class="mute-icon mic-icon"></div>
				</button>
				<button id="muteAudio" class="mute-button">
					<div class="mute-icon speaker-icon"></div>
				</button>
				<button id="muteVideo" class="mute-button">
					<div class="mute-icon video-icon"></div>
				</button>
			</div>
			<button id="startButton">Start and Connect</button>
			<select id="responseType">
				<option value="audio" selected>Audio Response</option>
				<option value="text">Text Response</option>
			</select>
			<select id="voiceSelect" style="display: none;">
				<option value="Aoede">Female Voice 1 (Aoede)</option>
				<option value="Kore">Female Voice 2 (Kore)</option>
				<option value="Puck">Male Voice 1 (Puck)</option>
				<option value="Charon">Male Voice 2 (Charon)</option>
				<option value="Fenrir">Male Voice 3 (Fenrir)</option>
			</select>
			<textarea placeholder="This is where you can specify an initial instruction prompt." id="systemPrompt" rows="4" style="width: 100%; background: #2a2a2a; color: #e0e0e0; border: 1px solid #404040; border-radius: 8px; padding: 8px; font-family: inherit;"></textarea>
			<div class="api-key-container">
				<input type="password" id="apiKey" placeholder="Enter Gemini API Key" size="15" class="api-key">
				<div class="api-key-info">
					Get your free Gemini API key at <a href="https://aistudio.google.com/app/apikey" target="_blank" rel="noopener">Google AI Studio</a>.
				</div>
			</div>        </div>
        <div id="error"></div>
        <video class="preview" id="preview" autoplay muted></video>
    </div>
    <div class="right-panel">
        <div class="chat-container">
            <div id="responses" class="responses"></div>
            <div class="input-container">
                <input type="text" class="message-input" placeholder="Type a message...">
                <button id="sendButton" title="You must Start the Stream before you can interact with the AI">Send</button>
            </div>
        </div>
    </div>
	<a href="https://github.com/steveseguin/gemini-chatbot" class="github-link" target="_blank" rel="noopener noreferrer" title="Fork on GitHub (MIT License)">
		<svg width="24" height="24" viewBox="0 0 24 24" fill="#e0e0e0">
			<path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
		</svg>
	</a>
	<div id="puppet-container"></div>
<script>

class PuppetAvatar {
    constructor(containerSelector) {
        this.container = document.querySelector(containerSelector);
        this.container.style.position = 'fixed';
        this.initializePuppet();
        this.currentEmotion = '';
        this.isTalking = false;
        this.BLINK_INTERVAL = 4000;
        this.BLINK_DURATION = 150;
        this.isDragging = false;
        this.dragOffset = { x: 0, y: 0 };
        this.startBlinking();
        this.initializeDragging();
    }

    initializePuppet() {
        this.container.innerHTML = `
            <div class="puppet">
                <div class="face">
                    <div class="eyebrows">
                        <div class="eyebrow"></div>
                        <div class="eyebrow"></div>
                    </div>
                    <div class="eyes">
                        <div class="eye"></div>
                        <div class="eye"></div>
                    </div>
                    <div class="cheeks">
                        <div class="cheek"></div>
                        <div class="cheek"></div>
                    </div>
                    <div class="mouth"></div>
                </div>
                <div class="shadow"></div>
            </div>`;
        this.puppet = this.container.querySelector('.puppet');
    }

    initializeDragging() {
		this.container.style.cursor = 'grab';
		const scale = 0.5; // Match the scale from CSS
		
		this.container.addEventListener('mousedown', (e) => {
			this.isDragging = true;
			this.container.style.cursor = 'grabbing';
			const rect = this.container.getBoundingClientRect();
			
			// Account for the scale in the offset calculation
			this.dragOffset = {
				x: (e.clientX - rect.left) * (1 / scale),
				y: (e.clientY - rect.top) * (1 / scale)
			};
		});

		document.addEventListener('mousemove', (e) => {
			if (!this.isDragging) return;
			
			// Account for scale when calculating new position
			const x = (e.clientX * (1 / scale)) - this.dragOffset.x;
			const y = (e.clientY * (1 / scale)) - this.dragOffset.y;
			
			// Scale the container dimensions for boundary checking
			const containerWidth = this.container.offsetWidth * scale;
			const containerHeight = this.container.offsetHeight * scale;
			
			this.setPosition(
				Math.max(0, Math.min(window.innerWidth - containerWidth, x * scale)),
				Math.max(0, Math.min(window.innerHeight - containerHeight, y * scale))
			);
		});

		document.addEventListener('mouseup', () => {
			this.isDragging = false;
			this.container.style.cursor = 'grab';
		});

		window.addEventListener('resize', () => {
			const rect = this.container.getBoundingClientRect();
			const containerWidth = this.container.offsetWidth * scale;
			const containerHeight = this.container.offsetHeight * scale;
			
			this.setPosition(
				Math.min(window.innerWidth - containerWidth, rect.left),
				Math.min(window.innerHeight - containerHeight, rect.top)
			);
		});
	}

    setEmotion(emotion, talking = false) {
        this.currentEmotion = emotion;
        this.isTalking = talking;
        this.updateState();
        
        if (emotion === 'sleepy') {
            this.stopBlinking();
            this.startSlowBlinking();
        } else {
            this.startBlinking();
        }
    }

    updateState() {
        const classes = [this.currentEmotion];
        if (this.isTalking) classes.push('talking');
        this.puppet.className = 'puppet ' + classes.join(' ');
    }

    blink() {
        this.puppet.classList.add('blink');
        setTimeout(() => this.puppet.classList.remove('blink'), this.BLINK_DURATION);
    }

    startBlinking() {
        if (this.blinkInterval) clearInterval(this.blinkInterval);
        this.blinkInterval = setInterval(() => {
            this.blink();
            if (Math.random() > 0.7) {
                setTimeout(() => this.blink(), 150);
            }
        }, this.BLINK_INTERVAL + Math.random() * 2000);
    }

    startSlowBlinking() {
        if (this.blinkInterval) clearInterval(this.blinkInterval);
        this.blinkInterval = setInterval(() => this.blink(), this.BLINK_INTERVAL * 2);
    }

    stopBlinking() {
        if (this.blinkInterval) {
            clearInterval(this.blinkInterval);
            this.blinkInterval = null;
        }
    }

    setTheme(theme) {
        document.documentElement.setAttribute('data-theme', theme);
    }

	setPosition(x, y) {
		this.container.style.left = typeof x === 'number' ? `${x}px` : x;
		this.container.style.top = typeof y === 'number' ? `${y}px` : y;
	}

    destroy() {
        this.stopBlinking();
        document.removeEventListener('mousemove', this.handleMouseMove);
        document.removeEventListener('mouseup', this.handleMouseUp);
        window.removeEventListener('resize', this.handleResize);
        this.container.innerHTML = '';
    }
}

class ChatGPTPublisher {
    constructor(stream, apiKey) {
        this.stream = stream;
        this.apiKey = apiKey;
        this.ws = null;
        this.audioContext = null;
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.handleMessage = this.handleMessage.bind(this);
        this.audioPlayer = new AudioPlayer();
        this.videoProcessor = null;
        this.canvasContext = null;
        this.lastImageTime = 0;
        this.imageInterval = 200;
        this.imageWidth = 640;
        this.imageHeight = 360;
    }

	setupVideoProcessing() {
		const videoTrack = this.stream.getVideoTracks()[0];
		if (!videoTrack) {
			console.log('No video track available - skipping video processing');
			return;
		}

		const canvas = document.createElement('canvas');
		canvas.width = this.imageWidth;
		canvas.height = this.imageHeight;
		this.canvasContext = canvas.getContext('2d');

		const videoElement = document.createElement('video');
		videoElement.srcObject = new MediaStream([videoTrack]);
		videoElement.autoplay = true;

		let animationFrame;
		const captureFrame = () => {
			if (this.stopped || !this.canvasContext) {
				if (animationFrame) {
					cancelAnimationFrame(animationFrame);
				}
				return;
			}

			const now = Date.now();
			if (now - this.lastImageTime >= this.imageInterval) {
				this.canvasContext.drawImage(videoElement, 0, 0, this.imageWidth, this.imageHeight);
				const base64Image = canvas.toDataURL('image/jpeg', 0.8).split(',')[1];
				
				this.sendMediaChunk([{
					mime_type: "image/jpeg",
					data: base64Image
				}]);
				this.lastImageTime = now;
			}

			animationFrame = requestAnimationFrame(captureFrame);
		};

		videoElement.addEventListener('loadedmetadata', () => {
			animationFrame = requestAnimationFrame(captureFrame);
		});
	}

    async handleMessage(event) {
        try {
            const data = JSON.parse(event.data);
            switch(data.type) {
                case 'response.text.delta':
                    const textEvent = new CustomEvent('modelResponse', {
                        detail: { text: data.delta }
                    });
                    window.dispatchEvent(textEvent);
                    break;
                case 'response.audio.delta':
                    if (data.delta) {
                        const audioData = base64ToArrayBuffer(data.delta);
                        this.audioPlayer.resume();
                        this.audioPlayer.addPCM16(new Uint8Array(audioData));
                    }
                    break;
            }
        } catch (err) {
            console.error('Error handling message:', err);
        }
    }
	
	handleConnectionFailure() {
		this.stop();
		const startButton = document.getElementById('startButton');
		const sendButton = document.getElementById('sendButton');
		const systemPrompt = document.getElementById('systemPrompt');
		
		startButton.textContent = 'Start Stream';
		startButton.dataset.started = "false";
		startButton.disabled = false;
		sendButton.disabled = true;
		systemPrompt.disabled = false;
	}
	
    async connect() {
        const uri = 'wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01';
        
        if (this.isConnected()) {
            console.log('Already connected');
            return;
        }

        this.ws = new WebSocket(uri);
        this.ws.onmessage = this.handleMessage;
		
		this.ws.onerror = (error) => {
			console.error('WebSocket error:', error);
			const errorMsg = 'Connection error occurred. Please check your API key and try again.';
			showError(errorMsg);
			this.handleConnectionFailure();
		};
		
		this.ws.onclose = (event) => {
			console.log('WebSocket closed:', event.code, event.reason);
			let errorMsg = 'Connection closed.';
			if (event.code === 1007) {
				errorMsg = 'Invalid API key. Please check your key and try again.';
			} else if (event.code === 1006) {
				errorMsg = 'Connection terminated unexpectedly. Please try again.';
			}
			showError(errorMsg);
			this.handleConnectionFailure();
		};

        await new Promise((resolve, reject) => {
            this.ws.addEventListener('open', resolve, { once: true });
            this.ws.addEventListener('error', reject, { once: true });
        });
		
		const systemPrompt = document.getElementById('systemPrompt');
        const setupMessage = {
            type: 'session.update',
            session: {
                modalities: ['text', 'audio'],
                instructions: systemPrompt.value
            }
        };
        this.ws.send(JSON.stringify(setupMessage));
    }
	

    sendPrompt(text) {
        if (!this.isConnected()) {
            console.error('WebSocket not connected');
            return;
        }

        this.ws.send(JSON.stringify({
            type: 'conversation.item.create',
            item: {
                type: 'message',
                role: 'user',
                content: [{
                    type: 'input_text',
                    text
                }]
            }
        }));
        this.ws.send(JSON.stringify({ type: 'response.create' }));
    }

    sendMediaChunk(mediaChunks) {
        if (!this.isConnected()) return;
        
        mediaChunks.forEach(chunk => {
            let content = [];
            
            if (chunk.mime_type.startsWith('audio/')) {
                content.push({
                    type: 'input_audio',
                    audio: chunk.data
                });
            } else if (chunk.mime_type.startsWith('image/')) {
                content.push({
                    type: 'image_url',
                    image_url: {
                        url: `data:${chunk.mime_type};base64,${chunk.data}`,
                        detail: 'auto'
                    }
                });
            }

            if (content.length > 0) {
                this.ws.send(JSON.stringify({
                    type: 'conversation.item.create',
                    item: {
                        type: 'message',
                        role: 'user',
                        content
                    }
                }));
            }
        });
        
        this.ws.send(JSON.stringify({ type: 'response.create' }));
    }

    isConnected() {
        return this.ws && this.ws.readyState === WebSocket.OPEN;
    }

	async start() {
        try {
            await this.connect();
            await this.setupAudioProcessing();
            const hasVideoTracks = this.stream.getVideoTracks().length > 0;
            if (hasVideoTracks) {
                this.setupVideoProcessing();
            }
        } catch (err) {
            console.error('Failed to start:', err);
            this.stop();
            throw err;
        }
    }

    async setupAudioProcessing() {
        this.audioContext = new AudioContext({ sampleRate: 16000 });
        const source = this.audioContext.createMediaStreamSource(this.stream);
        
        this.mediaRecorder = new MediaRecorder(this.stream);
        this.mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                this.audioChunks.push(event.data);
            }
        };
        
        this.mediaRecorder.onstop = () => {
            const audioBlob = new Blob(this.audioChunks, { type: 'audio/wav' });
            this.processAudioBlob(audioBlob);
            this.audioChunks = [];
        };
        
        this.mediaRecorder.start(1000);
    }

    async processAudioBlob(audioBlob) {
        const reader = new FileReader();
        reader.onloadend = () => {
            const base64Audio = reader.result.split(',')[1];
            this.sendMediaChunk([{
                mime_type: 'audio/wav',
                data: base64Audio
            }]);
        };
        reader.readAsDataURL(audioBlob);
    }
	
    stop() {
        this.stopped = true;
        if (this.mediaRecorder) {
            this.mediaRecorder.stop();
        }
        this.ws?.close();
        this.audioContext?.close();
        this.audioPlayer?.stop();
        this.ws = null;
        this.audioContext = null;
        this.mediaRecorder = null;
        this.videoProcessor = null;
        this.canvasContext = null;
    }
}
class GoogleLivePublisher {
    constructor(stream, apiKey) {
        this.stream = stream;
        this.apiKey = apiKey;
        this.ws = null;
        this.audioContext = null;
        this.videoProcessor = null;
        this.canvasContext = null;
        this.lastImageTime = 0;
        this.imageInterval = 200;
        this.imageWidth = 640;
        this.imageHeight = 360;
        this.handleMessage = this.handleMessage.bind(this);
        this.audioPlayer = new AudioPlayer();
    }
	
	handleConnectionFailure() {
		this.stop();
		const startButton = document.getElementById('startButton');
		const sendButton = document.getElementById('sendButton');
		const systemPrompt = document.getElementById('systemPrompt');
		
		startButton.textContent = 'Start Stream';
		startButton.dataset.started = "false";
		startButton.disabled = false;
		sendButton.disabled = true;
		systemPrompt.disabled = false;
	}

    async handleMessage(event) {
        try {
            let response;
            if (event.data instanceof Blob) {
                const text = await event.data.text();
                response = JSON.parse(text);
            } else {
                response = JSON.parse(event.data);
            }
            if (response.setupComplete) {
                console.log('Setup complete received');
                this.sendPrompt("Hi, introduce yourself in a sentence for me. Be friendly to me.");
            }
            if (response.serverContent?.modelTurn?.parts) {
                const parts = response.serverContent.modelTurn.parts;
                let hasAudioParts = false;
                parts.forEach(part => {
                    if (part.text) {
                        console.log('Model response:', part.text);
                        const event = new CustomEvent('modelResponse', {
                            detail: {
                                text: part.text
                            }
                        });
                        window.dispatchEvent(event);
                    }
                    if (part.inlineData && part.inlineData.mimeType.startsWith('audio/')) {
                        hasAudioParts = true;
                        console.log('Received audio response with mime type:', part.inlineData.mimeType);
                        try {
                            const rateMatch = part.inlineData.mimeType.match(/rate=(\d+)/);
                            const sampleRate = rateMatch ? parseInt(rateMatch[1]) : 24000;
                            this.audioPlayer.resume();
                            const audioData = base64ToArrayBuffer(part.inlineData.data);
                            console.log('Processing audio chunk of size:', audioData.byteLength);
                            this.audioPlayer.addPCM16(new Uint8Array(audioData));
                        } catch (err) {
                            console.error('Error processing audio:', err);
                        }
                    }
                });
                if (response.serverContent.turnComplete && hasAudioParts) {
                    console.log('Turn complete, finalizing audio');
                    this.audioPlayer.complete();
                }
            }
            if (!response.setupComplete && !response.serverContent) {
                console.log('Other response type:', response);
            }
        } catch (err) {
            console.error('Error handling message:', err);
        }
    }
    sendPrompt(text) {
        if (!this.isConnected()) {
            console.error('WebSocket not connected, attempting reconnect...');
            this.connect().then(() => {
                this._sendPromptInternal(text);
            });
            return;
        }
        this._sendPromptInternal(text);
    }
    _sendPromptInternal(text) {
        if (this.isConnected()) {
            const message = {
                clientContent: {
                    turns: [{
                        role: "user",
                        parts: [{
                            text
                        }]
                    }],
                    turnComplete: true
                }
            };
            console.log('Sending prompt:', message);
            this.ws.send(JSON.stringify(message));
        } else {
            console.error('WebSocket still not ready after reconnect attempt');
        }
    }
    sendMediaChunk(mediaChunks) {
        if (this.ws?.readyState === WebSocket.OPEN) {
            const message = {
                realtimeInput: {
                    mediaChunks: mediaChunks.map(chunk => ({
                        mimeType: chunk.inlineData.mimeType,
                        data: chunk.inlineData.data
                    }))
                }
            };
            this.ws.send(JSON.stringify(message));
        }
    }
    isConnected() {
        return this.ws && this.ws.readyState === WebSocket.OPEN;
    }
    async connect() {
        const host = 'generativelanguage.googleapis.com';
        const uri = `wss://${host}/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidiGenerateContent?key=${this.apiKey}`;
        if (this.isConnected()) {
            console.log('Already connected');
            return;
        }
        const responseType = document.getElementById('responseType');
        const voiceSelect = document.getElementById('voiceSelect');
        voiceSelect.style.display = responseType.value === 'audio' ? 'block' : 'none';
        this.ws = new WebSocket(uri);
        this.ws.onmessage = this.handleMessage;
		
		this.ws.onerror = (error) => {
			console.error('WebSocket error:', error);
			const errorMsg = 'Connection error occurred. Please check your API key and try again.';
			showError(errorMsg);
			this.handleConnectionFailure();
		};

		this.ws.onclose = (event) => {
			console.log('WebSocket closed:', event.code, event.reason);
			let errorMsg = 'Connection closed.';
			if (event.code === 1007) {
				errorMsg = 'Invalid API key. Please check your key and try again.';
			} else if (event.code === 1006) {
				errorMsg = 'Connection terminated unexpectedly. Please try again.';
			}
			showError(errorMsg);
			this.handleConnectionFailure();
		};
		
        await new Promise((resolve, reject) => {
            this.ws.addEventListener('open', resolve, {
                once: true
            });
            this.ws.addEventListener('error', reject, {
                once: true
            });
        });
		const systemPrompt = document.getElementById('systemPrompt');
        const setupMessage = {
            setup: {
                model: "models/gemini-2.0-flash-exp",
                systemInstruction: {
                    parts: [{
                        text: document.getElementById('systemPrompt').value
                    }]
                },
                generationConfig: {
                    temperature: 0.9,
                    topK: 1,
                    topP: 1,
                    candidateCount: 1,
                    responseModalities: responseType.value === 'audio' ? 'AUDIO' : 'TEXT',
                    ...(responseType.value === 'audio' && {
                        speechConfig: {
                            voiceConfig: {
                                prebuiltVoiceConfig: {
                                    voiceName: voiceSelect.value
                                }
                            }
                        }
                    })
                }
            }
        };
        console.log('Sending setup message:', setupMessage);
        this.ws.send(JSON.stringify(setupMessage));
    }
    async start() {
        try {
            await this.connect();
            await this.setupAudioProcessing();
            this.setupVideoProcessing();
        } catch (err) {
            console.error('Failed to start:', err);
            this.stop();
            throw err;
        }
    }
    async setupAudioProcessing() {
        this.audioContext = new AudioContext({
            sampleRate: 16000
        });
        const workletBlob = new Blob([`registerProcessor('audio-processor', ${AudioProcessingWorklet})`], {
            type: 'application/javascript'
        });
        const workletUrl = URL.createObjectURL(workletBlob);
        await this.audioContext.audioWorklet.addModule(workletUrl);
        URL.revokeObjectURL(workletUrl);
        const source = this.audioContext.createMediaStreamSource(this.stream);
        const processor = new AudioWorkletNode(this.audioContext, 'audio-processor');
        processor.port.onmessage = (event) => {
            if (event.data.data?.int16arrayBuffer) {
                const base64Audio = btoa(String.fromCharCode(...new Uint8Array(event.data.data.int16arrayBuffer)));
                this.sendMediaChunk([{
                    mime_type: "audio/pcm;rate=16000",
                    data: base64Audio
                }]);
            }
        };
        source.connect(processor);
    }
    setupVideoProcessing() {
		const videoTrack = this.stream.getVideoTracks()[0];
		if (!videoTrack) {
			console.log('No video track available - skipping video processing');
			return;
		}
		
		const canvas = document.createElement('canvas');
		canvas.width = this.imageWidth;
		canvas.height = this.imageHeight;
		this.canvasContext = canvas.getContext('2d');
		
		const videoElement = document.createElement('video');
		videoElement.srcObject = new MediaStream([videoTrack]);
		videoElement.autoplay = true;
		
		let animationFrame;
		const captureFrame = () => {
			if (this.stopped || !this.canvasContext) {
				if (animationFrame) {
					cancelAnimationFrame(animationFrame);
				}
				return;
			}
			
			const now = Date.now();
			if (now - this.lastImageTime >= this.imageInterval) {
				this.canvasContext.drawImage(videoElement, 0, 0, this.imageWidth, this.imageHeight);
				const base64Image = canvas.toDataURL('image/jpeg', 0.8).split(',')[1];
				this.sendMediaChunk([{
					mime_type: "image/jpeg",
					data: base64Image
				}]);
				this.lastImageTime = now;
			}
			
			animationFrame = requestAnimationFrame(captureFrame);
		};
		
		videoElement.addEventListener('loadedmetadata', () => {
			animationFrame = requestAnimationFrame(captureFrame);
		});
	}
    sendMediaChunk(mediaChunks) {
        if (this.ws?.readyState === WebSocket.OPEN) {
            const message = {
                realtimeInput: {
                    mediaChunks
                }
            };
            this.ws.send(JSON.stringify(message));
        }
    }
    stop() {
        this.stopped = true;
        this.ws?.close();
        this.audioContext?.close();
        this.audioPlayer?.stop();
        this.ws = null;
        this.audioContext = null;
        this.videoProcessor = null;
        this.canvasContext = null;
    }
}
class AudioPlayer {
    constructor() {
        this.context = new AudioContext({sampleRate: 24000});
        this.gainNode = this.context.createGain();
        this.gainNode.connect(this.context.destination);
        
        this.samples = new Float32Array(0);
        this.isPlaying = false;
        this.nextTime = 0;
        this.completeCalled = false;
		
		this.timeout = null;
    }

    addPCM16(chunk) {
        // Convert to float32
        const float32Array = new Float32Array(chunk.length / 2);
        const dataView = new DataView(chunk.buffer);
        for (let i = 0; i < chunk.length / 2; i++) {
            float32Array[i] = dataView.getInt16(i * 2, true) / 32768;
        }

        // Add to existing samples
        const newSamples = new Float32Array(this.samples.length + float32Array.length);
        newSamples.set(this.samples);
        newSamples.set(float32Array, this.samples.length);
        this.samples = newSamples;

        // Start playing if not already
        if (!this.isPlaying) {
            this.play();
        }
    }

    play() {
        if (this.samples.length === 0) return;
        this.isPlaying = true;

        // Create buffer for current samples
        const buffer = this.context.createBuffer(1, this.samples.length, this.context.sampleRate);
        buffer.getChannelData(0).set(this.samples);
        
        const source = this.context.createBufferSource();
        source.buffer = buffer;
        source.connect(this.gainNode);
        
        // Calculate start time
        const startTime = Math.max(this.context.currentTime, this.nextTime);
        source.start(startTime);
        this.nextTime = startTime + buffer.duration;
        
        // Reset samples buffer
        this.samples = new Float32Array(0);
        
        source.onended = () => {
            this.isPlaying = false;
            if (this.samples.length > 0) {
                this.play();
            } else if (this.completeCalled) {
                avatar.setEmotion('happy', false);
            } else {
				clearInterval(this.timeout);
				this.timeout = setTimeout(()=>{
					avatar.setEmotion('happy', false);
				},20);
			}
        };
		clearInterval(this.timeout);
        avatar.setEmotion("happy", true);
    }

    async resume() {
        if (this.context.state === "suspended") {
            await this.context.resume();
        }
    }

    stop() {
        this.samples = new Float32Array(0);
        this.isPlaying = false;
        this.nextTime = 0;
        this.completeCalled = false;
        
        this.gainNode.disconnect();
        this.gainNode = this.context.createGain();
        this.gainNode.connect(this.context.destination);
        clearInterval(this.timeout);
        avatar.setEmotion('happy', false);
    }

    complete() {
        this.completeCalled = true;
        if (!this.isPlaying && this.samples.length > 0) {
            this.play();
        }
		
    }
}
function base64ToArrayBuffer(base64) {
    const binaryString = atob(base64);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
}
class MessageFormatter {
    constructor() {
        this.currentMessage = '';
        this.currentMessageElement = null;
        this.messageBuffer = '';
        this.messageComplete = false;
        this.lastMessageTime = Date.now();
        this.pauseThreshold = 300;
    }
    formatMarkdown(text) {
        let formatted = text
            .replace(/\*\*\*(.*?)\*\*\*/g, '<strong><em>$1</em></strong>')
            .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>')
            .replace(/\*(.*?)\*/g, '<em>$1</em>')
            .replace(/`(.*?)`/g, '<code>$1</code>');
        const lines = formatted.split('\n');
        const formattedLines = lines.map(line => {
            if (line.trim().startsWith('*') && line.trim()[1] === ' ') {
                return `<li>${line.trim().substring(2)}</li>`;
            }
            if (/^\d+\./.test(line.trim())) {
                return `<li>${line.trim()}</li>`;
            }
            return line;
        });
        return formattedLines.join('\n')
            .replace(/\n\n/g, '<br><br>')
            .replace(/\n(?![<])/g, '<br>');
    }
    appendMessage(text, isUser = false) {
        const now = Date.now();
        if (isUser) {
            const messageDiv = document.createElement('div');
            messageDiv.className = 'message user-message';
            const contentDiv = document.createElement('div');
            contentDiv.className = 'markdown-content';
            contentDiv.textContent = text;
            messageDiv.appendChild(contentDiv);
            responsesDiv.appendChild(messageDiv);
            this.messageComplete = true;
            this.scrollToBottom();
            this.lastMessageTime = now;
            return;
        }
        if (this.currentMessageElement && (now - this.lastMessageTime > this.pauseThreshold)) {
            this.messageBuffer += '\n';
        }
        this.messageBuffer += text;
        this.lastMessageTime = now;
        if (!this.currentMessageElement) {
            this.currentMessageElement = document.createElement('div');
            this.currentMessageElement.className = 'message assistant-message';
            const contentDiv = document.createElement('div');
            contentDiv.className = 'markdown-content';
            this.currentMessageElement.appendChild(contentDiv);
            responsesDiv.appendChild(this.currentMessageElement);
        }
        const contentDiv = this.currentMessageElement.querySelector('.markdown-content');
        contentDiv.innerHTML = this.formatMarkdown(this.messageBuffer);
        if (
            this.messageBuffer.match(/\n\n$/) ||
            this.messageBuffer.match(/[.!?]\s+$/) ||
            this.messageBuffer.match(/\n\s*[-*]\s.*\n\n$/)
        ) {
            this.finalizeMessage();
        }
        this.scrollToBottom();
    }
    finalizeMessage() {
        this.messageBuffer = '';
        this.currentMessageElement = null;
        this.messageComplete = true;
        this.lastMessageTime = Date.now();
    }
    scrollToBottom() {
        responsesDiv.scrollTop = responsesDiv.scrollHeight;
    }
}
const AudioProcessingWorklet = `
		class AudioProcessor extends AudioWorkletProcessor {
		  buffer = new Int16Array(2048);
		  bufferWriteIndex = 0;
		  process(inputs) {
			if (inputs[0].length) {
			  const samples = inputs[0][0];
			  for (let i = 0; i < samples.length; i++) {
				const int16Value = samples[i] * 32768;
				this.buffer[this.bufferWriteIndex++] = int16Value;
				if(this.bufferWriteIndex >= this.buffer.length) {
				  this.port.postMessage({
					data: { int16arrayBuffer: this.buffer.buffer }
				  });
				  this.bufferWriteIndex = 0;
				}
			  }
			}
			return true;
		  }
		}`;
const messageFormatter = new MessageFormatter();
window.addEventListener('modelResponse', (event) => {
    console.log(event.detail.text);
    messageFormatter.appendMessage(event.detail.text);
});
let stream = null;
const videoSelect = document.getElementById('videoSource');
const audioSelect = document.getElementById('audioSource');
const preview = document.getElementById('preview');
const errorDisplay = document.getElementById('error');
const responsesDiv = document.getElementById('responses');
let publisher = null;

async function tryGetInitialPermissions() {
    try {
        // First try just audio, as it's less likely to be in use
        const audioStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
        audioStream.getTracks().forEach(track => track.stop());
        
        // Then try to get video separately
        try {
            const videoStream = await navigator.mediaDevices.getUserMedia({ audio: false, video: true });
            videoStream.getTracks().forEach(track => track.stop());
        } catch (videoErr) {
            console.log("Default video device unavailable, will try alternatives during enumeration");
        }
        
        await getDevices();
    } catch (audioErr) {
        try {
            // If audio failed, try video only
            const videoStream = await navigator.mediaDevices.getUserMedia({ audio: false, video: true });
            videoStream.getTracks().forEach(track => track.stop());
            await getDevices();
        } catch (err) {
            // If both audio and video fail individually, try with no initial devices
            console.warn("Could not access default devices, attempting enumeration anyway");
            await getDevices();
        }
    }
}

const apiKeyInput = document.getElementById('apiKey');
apiKeyInput.value = localStorage.getItem('apiKey') || '';
validateApiKey();

document.getElementById('apiKey').addEventListener('input', validateApiKey);

function validateApiKey() {
    const apiKey = apiKeyInput.value.trim();
    startButton.disabled = !apiKey;
    localStorage.setItem('apiKey', apiKey);
    return apiKey;
}

startButton.addEventListener('click', async () => {
    const apiKey = apiKeyInput.value.trim();

    if (!apiKey) {
        apiKeyInput.classList.add('highlight');
        setTimeout(() => apiKeyInput.classList.remove('highlight'), 2000);
        return;
    }

    try {
        if (publisher) {
            startButton.textContent = 'Starting...';
            startButton.disabled = true;
            
            // Proper cleanup when stopping
            publisher.stop();
            publisher = null;
            
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            
            if (currentAudioIndicator) {
                currentAudioIndicator.remove();
                currentAudioIndicator = null;
            }
            
            preview.srcObject = null;
            startButton.textContent = 'Start Stream';
            startButton.disabled = false;
            sendButton.disabled = true;
            document.getElementById('systemPrompt').disabled = false;
            return;
        }

        startButton.textContent = 'Starting...';
        startButton.disabled = true;

        stream = await getStream();
        preview.srcObject = stream;
        sessionStorage.setItem('apiKey', apiKey);
        
        const currentProvider = providerSelect.value;
        publisher = currentProvider === 'chatgpt' 
            ? new ChatGPTPublisher(stream, apiKey)
            : new GoogleLivePublisher(stream, apiKey);
            
        await publisher.start();
        startButton.textContent = 'Stop Stream';
        startButton.dataset.started = "true";
        startButton.disabled = false;
        sendButton.disabled = false;
        document.getElementById('systemPrompt').disabled = true;
        
        if (stream.getAudioTracks().length > 0) {
            setupAudioIndicator(stream);
        }
    } catch (err) {
        console.error(err);
        showError('Failed to start publishing: ' + err.message);
        startButton.textContent = 'Start Stream';
        startButton.dataset.started = "false";
        startButton.disabled = false;
        sendButton.disabled = true;
        document.getElementById('systemPrompt').disabled = false;
    }
});

let currentAudioIndicator = null;
let currentAudioContext = null;
let currentAnimationFrame = null;

function setupAudioIndicator(stream) {
    // Cleanup previous instance
    if (currentAudioIndicator) {
        currentAudioIndicator.remove();
        if (currentAudioContext) {
            currentAudioContext.close();
        }
        if (currentAnimationFrame) {
            cancelAnimationFrame(currentAnimationFrame);
        }
    }

    // Create new audio context and analyzers for different audio sources
    currentAudioContext = new AudioContext();
    const analyserMic = currentAudioContext.createAnalyser();
    const analyserSystem = currentAudioContext.createAnalyser();
    analyserMic.fftSize = 256;
    analyserSystem.fftSize = 256;

    // Create container for indicators
    const container = document.createElement('div');
    container.style.cssText = `
        width: 100%;
        display: flex;
        flex-direction: column;
        gap: 4px;
        margin-top: 8px;
    `;

    // Create separate indicators for mic and system audio
    const micIndicator = document.createElement('div');
    const systemIndicator = document.createElement('div');
    
    const baseIndicatorStyle = `
        width: 100%;
        height: 4px;
        background: #333;
        border-radius: 2px;
        overflow: hidden;
        position: relative;
    `;
    
    micIndicator.style.cssText = baseIndicatorStyle;
    systemIndicator.style.cssText = baseIndicatorStyle;

    // Add labels
    const micLabel = document.createElement('div');
    const systemLabel = document.createElement('div');
    micLabel.textContent = 'Microphone';
    systemLabel.textContent = 'System Audio';
    micLabel.style.cssText = 'font-size: 12px; color: #999; margin-bottom: 2px;';
    systemLabel.style.cssText = 'font-size: 12px; color: #999; margin-bottom: 2px; margin-top: 4px;';

    // Organize elements
    container.appendChild(micLabel);
    container.appendChild(micIndicator);
    container.appendChild(systemLabel);
    container.appendChild(systemIndicator);
    preview.insertAdjacentElement('afterend', container);
    currentAudioIndicator = container;

    // Process audio tracks
    stream.getAudioTracks().forEach(track => {
        const source = currentAudioContext.createMediaStreamSource(new MediaStream([track]));
        if (track.label && track.label.toLowerCase().includes('system')) {
            source.connect(analyserSystem);
        } else {
            source.connect(analyserMic);
        }
    });

    const micData = new Uint8Array(analyserMic.frequencyBinCount);
    const systemData = new Uint8Array(analyserSystem.frequencyBinCount);

    function updateIndicators() {
        if (!stream.active) {
            container.remove();
            currentAudioIndicator = null;
            currentAudioContext = null;
            cancelAnimationFrame(currentAnimationFrame);
            return;
        }

        // Update microphone level
        analyserMic.getByteFrequencyData(micData);
        const micLevel = Math.min(100, (micData.reduce((a, b) => a + b) / micData.length / 128) * 100);
        micIndicator.style.background = `linear-gradient(90deg, #4CAF50 ${micLevel}%, #333 ${micLevel}%)`;

        // Update system audio level
        analyserSystem.getByteFrequencyData(systemData);
        const systemLevel = Math.min(100, (systemData.reduce((a, b) => a + b) / systemData.length / 128) * 100);
        systemIndicator.style.background = `linear-gradient(90deg, #2196F3 ${systemLevel}%, #333 ${systemLevel}%)`;

        currentAnimationFrame = requestAnimationFrame(updateIndicators);
    }

    updateIndicators();
}

videoSelect.addEventListener('change', async () => {
    await updateMediaStream();
});

audioSelect.addEventListener('change', async () => {
    await updateMediaStream();
});

async function getDevices() {
    try {
        const devices = await navigator.mediaDevices.enumerateDevices();
        
        // Clear existing options
        videoSelect.innerHTML = '';
        audioSelect.innerHTML = '';
        
        // Filter devices
        const videoDevices = devices.filter(d => d.kind === 'videoinput');
        const audioDevices = devices.filter(d => d.kind === 'audioinput');
        
        // Add no input options
        videoSelect.appendChild(new Option('No Video', 'none'));
        audioSelect.appendChild(new Option('No Audio', 'none'));
        
        // Add screen share option
        videoSelect.appendChild(new Option('Screen Share', 'screen'));
        
        // Add remaining device options
        videoDevices.forEach(device => {
            videoSelect.appendChild(new Option(device.label || `Camera ${videoSelect.length}`, device.deviceId));
        });
        
        audioDevices.forEach(device => {
            audioSelect.appendChild(new Option(device.label || `Microphone ${audioSelect.length}`, device.deviceId));
        });

        // Try to find an available video device
        if (videoDevices.length > 0) {
            for (const device of videoDevices) {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({
                        video: { deviceId: { exact: device.deviceId } }
                    });
                    stream.getTracks().forEach(track => track.stop());
                    videoSelect.value = device.deviceId;
                    break;
                } catch (err) {
                    console.warn(`Video device ${device.label || device.deviceId} unavailable:`, err.message);
                    continue;
                }
            }
            // If no video devices are available, default to screen share
            if (!videoSelect.value) {
                videoSelect.value = 'screen';
            }
        } else {
            videoSelect.value = 'screen';
        }

        // Try to find an available audio device
        if (audioDevices.length > 0) {
            for (const device of audioDevices) {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({
                        audio: { deviceId: { exact: device.deviceId } }
                    });
                    stream.getTracks().forEach(track => track.stop());
                    audioSelect.value = device.deviceId;
                    break;
                } catch (err) {
                    console.warn(`Audio device ${device.label || device.deviceId} unavailable:`, err.message);
                    continue;
                }
            }
            // If no audio devices are available, default to no audio
            if (!audioSelect.value) {
                audioSelect.value = 'none';
            }
        }

        // Show initial preview with the selected devices
        await updateMediaStream();
        
    } catch (err) {
        showError('Failed to get devices: ' + err.message);
    }
}

let micMuted = false;
let audioMuted = false;
let videoMuted = false;

const muteMicButton = document.getElementById('muteMic');
const muteAudioButton = document.getElementById('muteAudio');
const muteVideoButton = document.getElementById('muteVideo');

muteVideoButton.addEventListener('click', () => {
    if (stream) {
        const videoTracks = stream.getVideoTracks();
        videoTracks.forEach(track => {
            track.enabled = videoMuted;
        });
        videoMuted = !videoMuted;
        muteVideoButton.classList.toggle('muted');
        muteVideoButton.querySelector('.video-icon').classList.toggle('muted');
    }
});

muteMicButton.addEventListener('click', () => {
    if (stream) {
        const audioTracks = stream.getAudioTracks();
        audioTracks.forEach(track => {
            if (track.kind === 'audio' && track.label && !track.label.toLowerCase().includes('system')) {
                track.enabled = micMuted;
            }
        });
        micMuted = !micMuted;
        muteMicButton.classList.toggle('muted');
        muteMicButton.querySelector('.mic-icon').classList.toggle('muted');
    }
});

muteAudioButton.addEventListener('click', () => {
    if (stream) {
        const audioTracks = stream.getAudioTracks();
        audioTracks.forEach(track => {
            if (track.kind === 'audio' && track.label && track.label.toLowerCase().includes('system')) {
                track.enabled = audioMuted;
            }
        });
        audioMuted = !audioMuted;
        muteAudioButton.classList.toggle('muted');
        muteAudioButton.querySelector('.speaker-icon').classList.toggle('muted');
    }
});

let audioContext;

async function getStream() {
    try {
        // Stop any existing tracks in the preview
        if (preview.srcObject) {
            preview.srcObject.getTracks().forEach(track => track.stop());
            preview.srcObject = null;
        }

        // Stop any existing tracks in the current stream
        if (stream) {
            stream.getTracks().forEach(track => track.stop());
        }

        let videoStream = null;
        let micStream = null;
        const outputStream = new MediaStream();

        // Handle video source
        if (videoSelect.value === 'screen') {
            try {
                videoStream = await navigator.mediaDevices.getDisplayMedia({
                    video: true,
                    audio: true
                });

                const videoTrack = videoStream.getVideoTracks()[0];
                if (videoTrack) {
                    // Remove any existing video tracks
                    outputStream.getVideoTracks().forEach(track => {
                        outputStream.removeTrack(track);
                        track.stop();
                    });
                    outputStream.addTrack(videoTrack);
                }
            } catch (err) {
                console.error('Screen share failed:', err);
                // Reset video select to 'none' if screen share fails
                videoSelect.value = 'none';
            }
        } else if (videoSelect.value !== 'none') {
            try {
                videoStream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        deviceId: { exact: videoSelect.value }
                    }
                });

                const videoTrack = videoStream.getVideoTracks()[0];
                if (videoTrack) {
                    // Remove any existing video tracks
                    outputStream.getVideoTracks().forEach(track => {
                        outputStream.removeTrack(track);
                        track.stop();
                    });
                    outputStream.addTrack(videoTrack);
                }
            } catch (err) {
                console.warn('Selected video device failed:', err);
                videoSelect.value = 'none';
            }
        }

        // Handle audio with cleanup
        if (audioSelect.value !== 'none') {
            try {
                micStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        deviceId: { exact: audioSelect.value },
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });

                // Clean up existing audio tracks
                outputStream.getAudioTracks().forEach(track => {
                    outputStream.removeTrack(track);
                    track.stop();
                });

                if (videoStream?.getAudioTracks().length > 0) {
                    // Handle system audio from screen share
                    const ctx = new AudioContext();
                    const dest = ctx.createMediaStreamDestination();

                    const systemSource = ctx.createMediaStreamSource(videoStream);
                    const micSource = ctx.createMediaStreamSource(micStream);

                    systemSource.connect(dest);
                    micSource.connect(dest);

                    const mixedTrack = dest.stream.getAudioTracks()[0];
                    if (mixedTrack) {
                        // Add custom label for mixed audio
                        mixedTrack.label = "Mixed Audio (System + Microphone)";
                        outputStream.addTrack(mixedTrack);
                    }

                    // Stop individual tracks after mixing
                    videoStream.getAudioTracks().forEach(track => track.stop());
                    micStream.getAudioTracks().forEach(track => track.stop());
                } else {
                    // Just microphone audio
                    const audioTrack = micStream.getAudioTracks()[0];
                    if (audioTrack) {
                        outputStream.addTrack(audioTrack);
                    }
                }
            } catch (err) {
                console.warn('Selected audio device failed:', err);
                audioSelect.value = 'none';
            }
        } else if (videoStream?.getAudioTracks().length > 0) {
            // Only system audio from screen share
            const systemTrack = videoStream.getAudioTracks()[0];
            if (systemTrack) {
                // Remove any existing audio tracks
                outputStream.getAudioTracks().forEach(track => {
                    outputStream.removeTrack(track);
                    track.stop();
                });
                outputStream.addTrack(systemTrack);
            }
        }

        return outputStream;
    } catch (err) {
        showError('Failed to get stream: ' + err.message);
        throw err;
    }
}

async function updateMediaStream() {
    try {
        const previousMicMuted = micMuted;
        const previousAudioMuted = audioMuted;

        // Get new stream with automatic cleanup of old tracks
        const newStream = await getStream();

        // Set preview
        preview.srcObject = newStream;

        if (publisher) {
            // Store old stream for cleanup
            const oldStream = stream;
            stream = newStream;

            const apiKey = apiKeyInput.value;
            const currentProvider = providerSelect.value;

            // Stop publisher and clean up
            await publisher.stop();
            publisher = null;

            // Clean up old stream after publisher is stopped
            if (oldStream) {
                oldStream.getTracks().forEach(track => track.stop());
            }

            // Create new publisher
            publisher = currentProvider === 'chatgpt' 
                ? new ChatGPTPublisher(stream, apiKey)
                : new GoogleLivePublisher(stream, apiKey);
            await publisher.start();
        } else {
            stream = newStream;
        }

        // Setup audio indicator if we have audio tracks
        if (stream.getAudioTracks().length > 0) {
            setupAudioIndicator(stream);
        }

        // Handle mute states
        if (previousMicMuted || previousAudioMuted) {
            const audioTracks = stream.getAudioTracks();
            audioTracks.forEach(track => {
                if (track.kind === 'audio' && track.label) {
                    if (previousMicMuted && !track.label.toLowerCase().includes('system')) {
                        track.enabled = false;
                    }
                    if (previousAudioMuted && track.label.toLowerCase().includes('system')) {
                        track.enabled = false;
                    }
                }
            });
        }
    } catch (err) {
        console.error('Failed to update media stream:', err);
        showError('Failed to update media stream: ' + err.message);
        
        // Reset states and cleanup on error
        if (publisher) {
            publisher.stop();
            publisher = null;
        }
        if (stream) {
            stream.getTracks().forEach(track => track.stop());
            stream = null;
        }
        if (preview.srcObject) {
            preview.srcObject.getTracks().forEach(track => track.stop());
            preview.srcObject = null;
        }
        
        // Reset UI states
        startButton.textContent = 'Start Stream';
        startButton.dataset.started = "false";
        startButton.disabled = false;
        sendButton.disabled = true;
        document.getElementById('systemPrompt').disabled = false;
    }
}

function showError(message) {
	errorDisplay.textContent = message;
	errorDisplay.style.display = 'block';
	errorDisplay.style.padding = '10px';
	errorDisplay.style.marginBottom = '10px';
	errorDisplay.style.backgroundColor = 'rgba(255, 0, 0, 0.1)';
	errorDisplay.style.border = '1px solid #ff6b6b';
	errorDisplay.style.borderRadius = '8px';
	
	// Clear error after 5 seconds
	setTimeout(() => {
		errorDisplay.style.display = 'none';
		errorDisplay.textContent = '';
	}, 5000);
}

if (!navigator.mediaDevices?.getUserMedia) {
    showError('getUserMedia not supported');
} else {
    // Try audio first since it's less likely to be in use
    navigator.mediaDevices.getUserMedia({ audio: true, video: false })
        .then(audioStream => {
            audioStream.getTracks().forEach(track => track.stop());
            // Then try video
            return navigator.mediaDevices.getUserMedia({ video: true, audio: false })
                .catch(videoErr => {
                    console.log("Default video unavailable, continuing with enumeration");
                });
        })
        .then(videoStream => {
            if (videoStream) videoStream.getTracks().forEach(track => track.stop());
        })
        .catch(err => {
            console.warn("Initial device check failed:", err);
        })
        .finally(() => {
            getDevices();
        });
        
    navigator.mediaDevices.addEventListener('devicechange', getDevices);
}

const messageInput = document.querySelector('.message-input');
const sendButton = document.querySelector('#sendButton');
sendButton.disabled = true;
responsesDiv.parentElement.insertBefore(messageInput, responsesDiv);
responsesDiv.parentElement.insertBefore(sendButton, responsesDiv);

sendButton.addEventListener('click', async () => {
    if (!publisher || sendButton.disabled) {
        showError('Please start the stream first');
        return;
    }
    if (messageInput.value.trim()) {
        try {
            messageFormatter.appendMessage(messageInput.value, true);
            await publisher.sendPrompt(messageInput.value);
            messageInput.value = '';
        } catch (err) {
            console.error('Failed to send message:', err);
            showError('Failed to send message: ' + err.message);
        }
    }
});

document.getElementById('voiceSelect').addEventListener('change', async () => {
    if (publisher && startButton.textContent === 'Stop Stream') {
        startButton.textContent = 'Starting...';
        startButton.disabled = true;
        publisher.stop();
        publisher = null;
        try {
            const stream = await getStream();
            preview.srcObject = stream;
            const apiKey = document.getElementById('apiKey').value;
            publisher = new GoogleLivePublisher(stream, apiKey);
            await publisher.start();
            startButton.textContent = 'Stop Stream';
            startButton.disabled = false;
			startButton.dataset.started = "true";
			sendButton.disabled = false;
            document.getElementById('systemPrompt').disabled = true;
        } catch (err) {
            console.error(err);
            showError('Failed to restart with new voice: ' + err.message);
            startButton.textContent = 'Start Stream';
            startButton.disabled = false;
			startButton.dataset.started = "false";
			sendButton.disabled = true;
			document.getElementById('systemPrompt').disabled = false;
        }
    }
});
document.getElementById('responseType').addEventListener('change', function() {
    const voiceSelect = document.getElementById('voiceSelect');
    voiceSelect.style.display = this.value === 'audio' ? 'block' : 'none';
    if (publisher && startButton.textContent === 'Stop Stream') {
        startButton.textContent = 'Starting...';
        startButton.disabled = true;
        publisher.stop();
        publisher = null;
        (async () => {
            try {
                const stream = await getStream();
                preview.srcObject = stream;
                const apiKey = document.getElementById('apiKey').value;
                publisher = new GoogleLivePublisher(stream, apiKey);
                await publisher.start();
                startButton.textContent = 'Stop Stream';
				startButton.dataset.started = "true";
                startButton.disabled = false;
				sendButton.disabled = false;
				document.getElementById('systemPrompt').disabled = true;
				
				if (audioContext) {
					audioContext.close();
					audioContext = null;
				}
            } catch (err) {
                console.error(err);
                showError('Failed to restart with new response type: ' + err.message);
                startButton.textContent = 'Start Stream';
				startButton.dataset.started = "false";
                startButton.disabled = false;
				sendButton.disabled = true;
				document.getElementById('systemPrompt').disabled = false;
            }
        })();
    }
});
messageInput.addEventListener('keypress', (e) => {
    if (e.key === 'Enter') {
        sendButton.click();
    }
});

const providerSelect = document.createElement('select');
providerSelect.id = 'providerSelect';
providerSelect.innerHTML = `
    <option value="gemini">Google Gemini</option>
    <option value="chatgpt">ChatGPT</option>
`;

// Insert provider select before API key input
const apiKeyContainer = document.querySelector('.api-key-container');
apiKeyContainer.parentElement.insertBefore(providerSelect, apiKeyContainer);


const defaultPrompts = {
    gemini: "You are a friendly social chat assistant that can see and hear the user. Avoid describing what you see unless asked.",
    chatgpt: "You are a friendly and helpful social chat assistant that can see and hear the user."
};

// Add system prompt container after provider select
const systemPrompt = document.getElementById('systemPrompt');
systemPrompt.value = defaultPrompts.gemini;

// Save to localStorage if available
if (localStorage) {
    const savedPrompts = localStorage.getItem('systemPrompts');
    if (savedPrompts) {
        const prompts = JSON.parse(savedPrompts);
        Object.assign(defaultPrompts, prompts);
        systemPrompt.value = defaultPrompts[providerSelect.value];
    }
}

systemPrompt.addEventListener('change', function() {
    defaultPrompts[providerSelect.value] = this.value;
    if (localStorage) {
        localStorage.setItem('systemPrompts', JSON.stringify(defaultPrompts));
    }
});

providerSelect.addEventListener('change', function() {
    const apiKeyInfo = document.querySelector('.api-key-info');
    systemPrompt.value = defaultPrompts[this.value];
    
    if (this.value === 'chatgpt') {
        apiKeyInput.placeholder = 'Enter ChatGPT API Key';
        apiKeyInfo.innerHTML = 'Get your ChatGPT API key at <a href="https://platform.openai.com/api-keys" target="_blank" rel="noopener">OpenAI</a>';
    } else {
        apiKeyInput.placeholder = 'Enter Gemini API Key';
        apiKeyInfo.innerHTML = 'Get your free Gemini API key at <a href="https://aistudio.google.com/app/apikey" target="_blank" rel="noopener">Google AI Studio</a>';
    }
});

const avatar = new PuppetAvatar('#puppet-container');
avatar.setPosition('calc(100vw - 320px)', 'calc(100vh - 320px)');
avatar.setEmotion('happy', false);


var ipcRenderer = false;
var ElectronDesktopCapture = false;

try {
	ipcRenderer = require("electron").ipcRenderer;
	window.navigator.mediaDevices.getDisplayMedia = (constraints = false) => {
		return new Promise(async (resolve, reject) => {
			try {
				const sources = await ipcRenderer.sendSync("getSources", { types: ["screen", "window"] });
				const selectionElem = document.createElement("div");
				selectionElem.classList = "desktop-capturer-selection";

				selectionElem.innerHTML = `
				<div class="desktop-capturer-selection__scroller">
				  <ul class="desktop-capturer-selection__list">
					${sources
						.map(
							({ id, name, thumbnail, display_id, appIcon }) => `
					  <li class="desktop-capturer-selection__item">
						<button class="desktop-capturer-click desktop-capturer-selection__btn" data-id="${id}" title="${name}">
						  <img class="desktop-capturer-selection__thumbnail" src="${thumbnail.toDataURL()}" />
						  <span class="desktop-capturer-selection__name">${name}</span>
						</button>
					  </li>
					`
						)
						.join("")}
					<div id="alsoCaptureAudioParent1" style="text-align: center;margin: auto 5px;font-size: 120%;"><i class="las la-music" style="font-size:40px;"></i><br />Include Desktop Audio<br /><input id="alsoCaptureAudio" style="width:20px;height:20px;margin-top: 10px;" type="checkbox" checked></div>
					<div id="alsoCaptureAudioParent2" style="text-align: center;margin: auto 5px;font-size: 120%;display:none;"><i class="las la-music" style="font-size:40px;"></i><br />Audio capture not <br />supported on macOS</div>
					<button id="captureDesktopAudio" class="desktop-capturer-click" style="margin: 10px;"><i class="las la-music" style="font-size:40px;"></i><br />Capture ONLY<br />Desktop Audio</button>
					<button id="cancelscreenshare" style="margin: 10px; background-color: #7c1414; width: 100px;"><i class="las la-window-close" style="font-size:40px;"></i><br />Cancel</button>
				  </ul>
				</div>
			  `;
				document.body.appendChild(selectionElem);
				
				const isMac = navigator.platform.toLowerCase().includes('mac');
				if (isMac) {
					try {
						document.getElementById("captureDesktopAudio").style.display = "none";
						document.getElementById("alsoCaptureAudio").checked = false;
						document.getElementById("alsoCaptureAudioParent1").style.display = "none";
						document.getElementById("alsoCaptureAudioParent2").style.display = "inline-block";
					} catch(e){}
				}

				document.getElementById("cancelscreenshare").addEventListener("click", async () => {
					selectionElem.remove();
					reject(null);
				});
				document.querySelectorAll(".desktop-capturer-click").forEach(button => {
					button.addEventListener("click", async () => {
						try {
							if (button.id == "captureDesktopAudio") {
								var new_constraints = {
									audio: {
										mandatory: {
											chromeMediaSource: "desktop"
										}
									},
									video: {
										mandatory: {
											chromeMediaSource: "desktop"
										}
									}
								};
								new_constraints.video.mandatory.maxFrameRate = 1;
								
								const stream = await window.navigator.mediaDevices.getUserMedia(new_constraints);
								if (stream.getVideoTracks().length) {
									var track = stream.getVideoTracks()[0];
									stream.removeTrack(stream.getVideoTracks()[0]);
									track.stop();
								}
								resolve(stream);
								selectionElem.remove();
							} else {
								var audioStream = false;
								if (document.getElementById("alsoCaptureAudio") && document.getElementById("alsoCaptureAudio").checked) {
									var new_constraints = {
										audio: {
											mandatory: {
												chromeMediaSource: "desktop"
											}
										},
										video: {
											mandatory: {
												chromeMediaSource: "desktop"
											}
										}
									};
									new_constraints.video.mandatory.maxFrameRate = 1;
									audioStream = await window.navigator.mediaDevices.getUserMedia(new_constraints);
									if (audioStream.getVideoTracks().length) {
										var track = audioStream.getVideoTracks()[0];
										audioStream.removeTrack(audioStream.getVideoTracks()[0]);
										track.stop();
									}
								}

								const id = button.getAttribute("data-id");
								const source = sources.find(source => source.id === id);
								if (!source) {
									throw new Error(`Source with id ${id} does not exist`);
								}
								var new_constraints = {
									audio: false,
									video: {
										mandatory: {
											chromeMediaSource: "desktop",
											chromeMediaSourceId: source.id
										}
									}
								};
								try {
									if (constraints.video.width.ideal) {
										new_constraints.video.mandatory.maxWidth = constraints.video.width.ideal;
									}
								} catch (e) {}
								try {
									if (constraints.video.height.ideal) {
										new_constraints.video.mandatory.maxHeight = constraints.video.height.ideal;
									}
								} catch (e) {}
								try {
									if (constraints.video.frameRate.ideal) {
										new_constraints.video.mandatory.maxFrameRate = constraints.video.frameRate.ideal;
									}
								} catch (e) {}
								const stream = await window.navigator.mediaDevices.getUserMedia(new_constraints);

								if (audioStream && audioStream.getAudioTracks().length) {
									stream.addTrack(audioStream.getAudioTracks()[0]);
								}

								resolve(stream);
								selectionElem.remove();
							}
						} catch (err) {
							console.error("Error selecting desktop capture source:", err);
							reject(err);
						}
					});
				});
			} catch (err) {
				console.error("Error displaying desktop capture sources:", err);
				reject(err);
			}
		});
	};
	ElectronDesktopCapture = true;
} catch (e) {
	console.warn("Couldn't load electron's screen capture. Elevate the app's permission to allow it (right-click?)");
}

</script>
</body>
</html>

